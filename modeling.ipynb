{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import iqr, randint, uniform\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "import gc\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "%load_ext autotime\n",
    "\n",
    "gc.enable()\n",
    "np.random.seed(235)\n",
    "\n",
    "path = \"/Users/dsaxton/home_credit_default/\"\n",
    "\n",
    "impute = Imputer(strategy=\"median\")\n",
    "quant = QuantileTransformer(output_distribution=\"normal\")\n",
    "stand = StandardScaler()\n",
    "\n",
    "def get_imp(clf, cols):\n",
    "    frame = (pd.DataFrame({\"Variable\": cols, \n",
    "                        \"Importance\": clf.feature_importances_}).\n",
    "             sort_values(by=\"Importance\", ascending=False).\n",
    "             reset_index(drop=True))\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 48.1 s\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path + \"train.csv\")\n",
    "sk_id_curr = df.pop(\"SK_ID_CURR\")\n",
    "y = df.pop(\"TARGET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(n_estimators=1000, num_leaves=23, subsample=0.5)\n",
    "clf.fit(df, y)\n",
    "\n",
    "lgb_cols = df.columns[clf.feature_importances_ > 0]\n",
    "len(lgb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXT_SOURCE_1_DIV_DAYS_BIRTH</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMT_CREDIT_DIV_AMT_ANNUITY</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVG_AGG_SYNTHETIC_TARGET</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Variable  Importance\n",
       "0                 EXT_SOURCE_3         325\n",
       "1                 EXT_SOURCE_2         320\n",
       "2  EXT_SOURCE_1_DIV_DAYS_BIRTH         217\n",
       "3   AMT_CREDIT_DIV_AMT_ANNUITY         210\n",
       "4     AVG_AGG_SYNTHETIC_TARGET         194"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40 ms\n"
     ]
    }
   ],
   "source": [
    "var_imp = get_imp(clf, df.columns)\n",
    "var_imp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's auc: 0.769725 + 0.00193869\n",
      "[200]\tcv_agg's auc: 0.776739 + 0.00170675\n",
      "[300]\tcv_agg's auc: 0.781761 + 0.00171266\n",
      "[400]\tcv_agg's auc: 0.784902 + 0.00175227\n"
     ]
    }
   ],
   "source": [
    "params = {\"n_estimators\": 5000, \n",
    "          \"num_leaves\": 500, \n",
    "          \"min_data_in_leaf\": 1000,\n",
    "          \"learning_rate\": 0.01, \n",
    "          \"bagging_fraction\": 0.5, \n",
    "          \"bagging_freq\": 1, \n",
    "          \"feature_fraction\": 0.5, \n",
    "          \"lambda_l2\": 1}\n",
    "\n",
    "to_drop = [c for c in df if \"PROJ\" in c]\n",
    "\n",
    "lgb_data = lgb.Dataset(data=df[lgb_cols].drop(to_drop, axis=1), \n",
    "                       label=y)\n",
    "\n",
    "cv_result = lgb.cv(params=params, \n",
    "                   train_set=lgb_data, \n",
    "                   nfold=5, \n",
    "                   metrics=\"auc\", \n",
    "                   early_stopping_rounds=200, \n",
    "                   stratified=True, \n",
    "                   shuffle=True, \n",
    "                   verbose_eval=100, \n",
    "                   show_stdv=True, \n",
    "                   seed=2357)\n",
    "\n",
    "cv_result = pd.DataFrame(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1...\n",
      "Fitting model 2...\n",
      "Fitting model 3...\n",
      "Fitting model 4...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',\n",
       "        class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
       "        lambda_l2=1, learning_rate=0.005, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001,\n",
       "        min_data_in_leaf=1000, min_split_gain=0.0, n_estimators=2500,\n",
       "        n_jobs=-1, num_leaves=500, objective=None, random_state=3572,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 4min 24s\n"
     ]
    }
   ],
   "source": [
    "lgb1 = lgb.LGBMClassifier(n_estimators=2500, \n",
    "                               num_leaves=500, \n",
    "                               min_data_in_leaf=1000,\n",
    "                               learning_rate=0.005, \n",
    "                               bagging_fraction=0.5, \n",
    "                               bagging_freq=1, \n",
    "                               feature_fraction=0.5, \n",
    "                               lambda_l2=1, \n",
    "                               random_state=2357) \n",
    "\n",
    "print(\"Fitting model 1...\")\n",
    "lgb1.fit(df, y)\n",
    "\n",
    "lgb2 = lgb.LGBMClassifier(n_estimators=2500, \n",
    "                               num_leaves=500, \n",
    "                               min_data_in_leaf=1000,\n",
    "                               learning_rate=0.005, \n",
    "                               bagging_fraction=0.5, \n",
    "                               bagging_freq=1, \n",
    "                               feature_fraction=0.5, \n",
    "                               lambda_l2=1, \n",
    "                               random_state=7235) \n",
    "\n",
    "print(\"Fitting model 2...\")\n",
    "lgb2.fit(df, y)\n",
    "\n",
    "lgb3 = lgb.LGBMClassifier(n_estimators=2500, \n",
    "                               num_leaves=500, \n",
    "                               min_data_in_leaf=1000,\n",
    "                               learning_rate=0.005, \n",
    "                               bagging_fraction=0.5, \n",
    "                               bagging_freq=1, \n",
    "                               feature_fraction=0.5, \n",
    "                               lambda_l2=1, \n",
    "                               random_state=5723) \n",
    "\n",
    "print(\"Fitting model 3...\")\n",
    "lgb3.fit(df, y)\n",
    "\n",
    "lgb4 = lgb.LGBMClassifier(n_estimators=2500, \n",
    "                               num_leaves=500, \n",
    "                               min_data_in_leaf=1000,\n",
    "                               learning_rate=0.005, \n",
    "                               bagging_fraction=0.5, \n",
    "                               bagging_freq=1, \n",
    "                               feature_fraction=0.5, \n",
    "                               lambda_l2=1, \n",
    "                               random_state=3572) \n",
    "\n",
    "print(\"Fitting model 4...\")\n",
    "lgb4.fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 263 ms\n"
     ]
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.36 s\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(path + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "sk_id_curr = test.pop(\"SK_ID_CURR\")\n",
    "\n",
    "scores = pd.DataFrame({\"SK_ID_CURR\": sk_id_curr, \n",
    "                      \"LGB_SCORE1\": lgb1.predict_proba(test)[:,1], \n",
    "                      \"LGB_SCORE2\": lgb2.predict_proba(test)[:,1], \n",
    "                      \"LGB_SCORE3\": lgb3.predict_proba(test)[:,1], \n",
    "                      \"LGB_SCORE4\": lgb4.predict_proba(test)[:,1]}, \n",
    "                     index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "scores[\"TARGET\"] = scores[[\"LGB_SCORE\" + str(i+1) for i in range(4)]].rank().apply(np.mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "scores[[\"SK_ID_CURR\", \"TARGET\"]].to_csv(path + \"submission.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
