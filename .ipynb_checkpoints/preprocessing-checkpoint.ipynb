{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 13.4 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, RobustScaler\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "%load_ext autotime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = None\n",
    "gc.enable()\n",
    "path = \"/Users/dsaxton/home_credit_default/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "def previous_agg_func(g):\n",
    "    mask6 = g[\"DAYS_DECISION\"] >= -180\n",
    "    mask12 = g[\"DAYS_DECISION\"] >= -360\n",
    "    mask24 = g[\"DAYS_DECISION\"] >= -720\n",
    "\n",
    "    d = {\n",
    "        \"AVG_PREV_AMT_CREDIT_DIV_AMT_ANNUITY_6M\": np.nanmean((g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"]).where(mask6)), \n",
    "        \"MIN_PREV_AMT_CREDIT_DIV_AMT_ANNUITY_6M\": np.nanmin((g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"]).where(mask6)), \n",
    "        \"MAX_PREV_AMT_CREDIT_DIV_AMT_ANNUITY_6M\": np.nanmax((g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"]).where(mask6)), \n",
    "        \"AVG_PREV_AMT_CREDIT_DIV_AMT_GOODS_PRICE_6M\": np.nanmean((g[\"AMT_CREDIT\"] / g[\"AMT_GOODS_PRICE\"]).where(mask6)), \n",
    "        \"MAX_PREV_AMT_CREDIT_DIV_AMT_GOODS_PRICE_6M\": np.nanmax((g[\"AMT_CREDIT\"] / g[\"AMT_GOODS_PRICE\"]).where(mask6)), \n",
    "        \"AVG_PREV_AMT_CREDIT_PLUS_AMT_ANNUITY_6M\": np.nanmean((g[\"AMT_CREDIT\"] + g[\"AMT_ANNUITY\"]).where(mask6)), \n",
    "        \"MIN_PREV_AMT_CREDIT_PLUS_AMT_ANNUITY_6M\": np.nanmin((g[\"AMT_CREDIT\"] + g[\"AMT_ANNUITY\"]).where(mask6)), \n",
    "        \"COUNT_NAME_CLIENT_TYPE_REPEATER_12M\": np.nansum((g[\"NAME_CLIENT_TYPE\"] == \"Repeater\").where(mask12)), \n",
    "        \"COUNT_NAME_CLIENT_TYPE_NEW_12M\": np.nansum((g[\"NAME_CLIENT_TYPE\"] == \"New\").where(mask12)), \n",
    "        \"SUM_NAME_PAYMENT_TYPE_XNA_6M\": np.nansum((g[\"NAME_PAYMENT_TYPE\"] == \"XNA\").where(mask6)), \n",
    "        \"SUM_NAME_SELLER_INDUSTRY_CSTR_6M\": np.nansum((g[\"NAME_SELLER_INDUSTRY\"] == \"Construction\").where(mask6)), \n",
    "        \"SUM_NAME_SELLER_INDUSTRY_XNA_6M\": np.nansum((g[\"NAME_SELLER_INDUSTRY\"] == \"XNA\").where(mask6)), \n",
    "        \"SUM_NAME_GOODS_CATEGORY_XNA_6M\": np.nansum((g[\"NAME_GOODS_CATEGORY\"] == \"XNA\").where(mask6)), \n",
    "        \"SUM_PRODUCT_COMBINATION_POS_MOBILE_INTEREST_12M\": np.nansum((g[\"PRODUCT_COMBINATION\"] == \"POS mobile with interest\").where(mask12)),\n",
    "        \"SUM_PRODUCT_COMBINATION_POS_HOUSE_INTEREST_12M\": np.nansum((g[\"PRODUCT_COMBINATION\"] == \"POS household with interest\").where(mask12)), \n",
    "        \"SUM_REFUSED_CONTRACT_6M\": np.nansum((g[\"NAME_CONTRACT_STATUS\"] == \"Refused\").where(mask12)), \n",
    "        \"AVG_RATE_INTEREST_PRIMARY_12M\": np.nanmean(g[\"RATE_INTEREST_PRIMARY\"].where(mask12)), \n",
    "        \"MAX_RATE_INTEREST_PRIMARY_12M\": np.nanmax(g[\"RATE_INTEREST_PRIMARY\"].where(mask12)), \n",
    "        \"MIN_RATE_INTEREST_PRIMARY_12M\": np.nanmin(g[\"RATE_INTEREST_PRIMARY\"].where(mask12)), \n",
    "        \"AVG_RATE_INTEREST_PRIVILEGED_12M\": np.nanmean(g[\"RATE_INTEREST_PRIVILEGED\"].where(mask12)), \n",
    "        \"MAX_UTILIZATION_3M\": np.nanmax((g[\"AMT_BALANCE\"] / g[\"AMT_CREDIT_LIMIT_ACTUAL\"]).where(mask3)),\n",
    "        \"MIN_PREV_AMT_ANNUITY_12M\": np.nanmin(g[\"AMT_ANNUITY\"].where(mask12)), \n",
    "        \"MIN_PREV_AMT_ANNUITY_24M\": np.nanmin(g[\"AMT_ANNUITY\"].where(mask24)), \n",
    "        \"MIN_PREV_PROP_APPROVED_12M\": np.nanmin((g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"]).where(mask12)), \n",
    "        \"AVG_SYNTH_TARGET_12M\": np.nanmean(g[\"SYNTHETIC_TARGET\"].where(mask12)), \n",
    "        \"AVG_PREV_PROP_APPROVED_12M\": np.nanmean((g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"]).where(mask12)), \n",
    "        \"AVG_PREV_PROP_APPROVED_24M\": np.nanmean((g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"]).where(mask24)), \n",
    "        \"MAX_PREV_PROP_APPROVED_12M\": np.nanmax((g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"]).where(mask12)), \n",
    "        \"MAX_PREV_PROP_APPROVED_24M\": np.nanmax((g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"]).where(mask24)), \n",
    "        \"COUNT_PREV_APP\": len(g), \n",
    "        \"MIN_PREV_DAYS_TERMINATION\": np.nanmin(g[\"DAYS_TERMINATION\"]), \n",
    "        \"MAX_PREV_DAYS_TERMINATION\": np.nanmax(g[\"DAYS_TERMINATION\"]), \n",
    "        \"AVG_PREV_DAYS_TERMINATION\": np.nanmean(g[\"DAYS_TERMINATION\"]), \n",
    "        \"RANGE_PREV_DAYS_TERMINATION\": np.nanmax(g[\"DAYS_TERMINATION\"]) - np.nanmin(g[\"DAYS_TERMINATION\"]),  \n",
    "        \"MIN_PREV_AMT_CREDIT\": np.nanmin(g[\"AMT_CREDIT\"]),\n",
    "        \"MAX_PREV_AMT_CREDIT\": np.nanmax(g[\"AMT_CREDIT\"]),\n",
    "        \"AVG_PREV_AMT_CREDIT\": np.nanmean(g[\"AMT_CREDIT\"]),\n",
    "        \"MIN_PREV_AMT_CREDIT_WEIGHTED\": np.nanmin(g[\"AMT_CREDIT\"] / abs(g[\"DAYS_DECISION\"])),\n",
    "        \"MAX_PREV_AMT_CREDIT_WEIGHTED\": np.nanmax(g[\"AMT_CREDIT\"] / abs(g[\"DAYS_DECISION\"])),\n",
    "        \"AVG_PREV_AMT_CREDIT_WEIGHTED\": np.nanmean(g[\"AMT_CREDIT\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"MIN_PREV_AMT_CREDIT_DIV_ANNUITY\": np.nanmin(g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"]),\n",
    "        \"MAX_PREV_AMT_CREDIT_DIV_ANNUITY\": np.nanmax(g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"]),\n",
    "        \"AVG_PREV_AMT_CREDIT_DIV_ANNUITY\": np.nanmean(g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"]),\n",
    "        \"MIN_PREV_AMT_CREDIT_DIV_ANNUITY_WEIGHTED\": np.nanmin(g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"] / abs(g[\"DAYS_DECISION\"])),\n",
    "        \"MAX_PREV_AMT_CREDIT_DIV_ANNUITY_WEIGHTED\": np.nanmax(g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"] / abs(g[\"DAYS_DECISION\"])),\n",
    "        \"AVG_PREV_AMT_CREDIT_DIV_ANNUITY_WEIGHTED\": np.nanmean(g[\"AMT_CREDIT\"] / g[\"AMT_ANNUITY\"] / abs(g[\"DAYS_DECISION\"])),  \n",
    "        \"MIN_PREV_AMT_ANNUITY\": np.nanmin(g[\"AMT_ANNUITY\"]), \n",
    "        \"MAX_PREV_AMT_ANNUITY\": np.nanmax(g[\"AMT_ANNUITY\"]), \n",
    "        \"AVG_PREV_AMT_ANNUITY\": np.nanmean(g[\"AMT_ANNUITY\"]), \n",
    "        \"MIN_PREV_AMT_ANNUITY_WEIGHTED\": np.nanmin(g[\"AMT_ANNUITY\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"MAX_PREV_AMT_ANNUITY_WEIGHTED\": np.nanmax(g[\"AMT_ANNUITY\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"AVG_PREV_AMT_ANNUITY_WEIGHTED\": np.nanmean(g[\"AMT_ANNUITY\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"MIN_DAYS_DECISION\": np.nanmin(g[\"DAYS_DECISION\"]), \n",
    "        \"MAX_DAYS_DECISION\": np.nanmax(g[\"DAYS_DECISION\"]), \n",
    "        \"RANGE_DAYS_DECISION\": np.nanmax(g[\"DAYS_DECISION\"]) - np.nanmin(g[\"DAYS_DECISION\"]),\n",
    "        \"SUM_DAYS_LAST_DUE_NULL\": np.nansum(g[\"DAYS_LAST_DUE\"].isnull()), \n",
    "        \"AVG_DAYS_LAST_DUE_NULL\": np.nanmean(g[\"DAYS_LAST_DUE\"].isnull()), \n",
    "        \"AVG_PREV_REQ_AMOUNT_WEIGHTED\": np.nanmean(g[\"AMT_APPLICATION\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"MAX_PREV_REQ_AMOUNT_WEIGHTED\": np.nanmax(g[\"AMT_APPLICATION\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"AVG_PREV_REQ_AMOUNT\": np.nanmean(g[\"AMT_APPLICATION\"]), \n",
    "        \"MAX_PREV_REQ_AMOUNT\": np.nanmax(g[\"AMT_APPLICATION\"]), \n",
    "        \"AVG_PREV_RATE_DOWNPAYMENT_WEIGHTED\": np.nanmean(g[\"RATE_DOWN_PAYMENT\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"AVG_PREV_PROP_APPROVED_WEIGHTED\": np.nanmean(g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"MAX_PREV_PROP_APPROVED_WEIGHTED\": np.nanmax(g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"AVG_PREV_RATE_DOWNPAYMENT\": np.nanmean(g[\"RATE_DOWN_PAYMENT\"]), \n",
    "        \"AVG_PREV_PROP_APPROVED\": np.nanmean(g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"]), \n",
    "        \"MAX_PREV_PROP_APPROVED\": np.nanmax(g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"]), \n",
    "        \"MIN_PREV_PROP_APPROVED\": np.nanmin(g[\"AMT_CREDIT\"] / g[\"AMT_APPLICATION\"]), \n",
    "        \"AVG_PREV_REQ_AMOUNT\": np.nanmean(g[\"AMT_APPLICATION\"]), \n",
    "        \"MAX_PREV_REQ_AMOUNT\": np.nanmax(g[\"AMT_APPLICATION\"]), \n",
    "        \"AVG_PREV_RATE_DOWNPAYMENT\": np.nanmean(g[\"RATE_DOWN_PAYMENT\"]), \n",
    "        \"AVG_PREV_INT_RATE\": np.nanmean(g[\"RATE_INTEREST_PRIMARY\"]), \n",
    "        \"SUM_PREV_URGENT_NEEDS\": np.nansum(g[\"NAME_CASH_LOAN_PURPOSE\"] == \"Urgent needs\"), \n",
    "        \"SUM_PREV_REPAIRS\": np.nansum(g[\"NAME_CASH_LOAN_PURPOSE\"] == \"Repairs\"), \n",
    "        \"SUM_PREV_OTHER\": np.nansum(g[\"NAME_CASH_LOAN_PURPOSE\"] == \"Other\"), \n",
    "        \"SUM_PREV_LIMIT_REJECT\": np.nansum(g[\"CODE_REJECT_REASON\"] == \"LIMIT\"), \n",
    "        \"SUM_REFUSED_CONTRACT\": np.nansum(g[\"NAME_CONTRACT_STATUS\"] == \"Refused\"), \n",
    "        \"SUM_CANC_CONTRACT\": np.nansum(g[\"NAME_CONTRACT_STATUS\"] == \"Canceled\"), \n",
    "        \"SUM_APPR_CONTRACT\": np.nansum(g[\"NAME_CONTRACT_STATUS\"] == \"Approved\"), \n",
    "        \"SUM_PREV_HC_REJECT\": np.nansum(g[\"CODE_REJECT_REASON\"] == \"HC\"), \n",
    "        \"SUM_PREV_INSURE_REQ\": np.nansum(g[\"NFLAG_INSURED_ON_APPROVAL\"]), \n",
    "        \"COUNT_PREV_WALK_IN\": np.nansum(g[\"NAME_PRODUCT_TYPE\"] == \"walk-in\"), \n",
    "        \"COUNT_PREV_HIGH_YIELD\": np.nansum(g[\"NAME_YIELD_GROUP\"] == \"high\"), \n",
    "        \"COUNT_PREV_LOW_YIELD\": np.nansum(g[\"NAME_YIELD_GROUP\"].apply(lambda x: x.startswith(\"low\"))), \n",
    "        \"AVG_SYNTH_TARGET\": np.nanmean(g[\"SYNTHETIC_TARGET\"]), \n",
    "        \"SUM_SYNTH_TARGET_WEIGHTED\": np.nansum(g[\"SYNTHETIC_TARGET\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"SUM_SYNTH_TARGET\": np.nansum(g[\"SYNTHETIC_TARGET\"]), \n",
    "        \"MAX_SYNTH_TARGET\": np.nanmax(g[\"SYNTHETIC_TARGET\"]), \n",
    "        \"MIN_SYNTH_TARGET\": np.nanmin(g[\"SYNTHETIC_TARGET\"]), \n",
    "        \"RANGE_SYNTH_TARGET\": np.nanmax(g[\"SYNTHETIC_TARGET\"]) - np.min(g[\"SYNTHETIC_TARGET\"]), \n",
    "        \"SUM_DAYS_LAST_DUE_1ST_VERSION_EQ_DAYS_LAST_DUE\": np.nansum(g[\"DAYS_LAST_DUE_1ST_VERSION\"] == g[\"DAYS_LAST_DUE\"]), \n",
    "        \"SUM_DAYS_FIRST_DRAWING_SENTINEL\": np.nansum(g[\"DAYS_FIRST_DRAWING_SENTINEL\"]), \n",
    "        \"SUM_DAYS_FIRST_DRAWING_SENTINEL_WEIGHTED\": np.nansum(g[\"DAYS_FIRST_DRAWING_SENTINEL\"] / abs(g[\"DAYS_DECISION\"])), \n",
    "        \"MAX_DAYS_FIRST_DRAWING_SENTINEL_WEIGHTED\": np.nanmax(g[\"DAYS_FIRST_DRAWING_SENTINEL\"] / abs(g[\"DAYS_DECISION\"])),         \n",
    "        \"SUM_DAYS_LAST_DUE_LT_FIRST_VERSION\": np.nansum(g[\"DAYS_LAST_DUE\"] < g[\"DAYS_LAST_DUE_1ST_VERSION\"]), \n",
    "    }\n",
    "\n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 49min 26s\n"
     ]
    }
   ],
   "source": [
    "previous_application = pd.read_csv(path + \"previous_application.csv\")\n",
    "\n",
    "with open(path + \"linear_model.pkl\", \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "impute = Imputer(strategy=\"median\")\n",
    "scale = StandardScaler()\n",
    "\n",
    "cols = [\"AMT_ANNUITY\", \n",
    "        \"AMT_CREDIT\", \n",
    "        \"AMT_GOODS_PRICE\", \n",
    "        \"HOUR_APPR_PROCESS_START\", \n",
    "        \"NAME_CONTRACT_TYPE\", \n",
    "        \"NAME_TYPE_SUITE\", \n",
    "        \"WEEKDAY_APPR_PROCESS_START\"]\n",
    "\n",
    "prev_temp = pd.get_dummies(previous_application[cols])\n",
    "\n",
    "dummy_cols = [\"AMT_CREDIT\",\n",
    "              \"AMT_GOODS_PRICE\",\n",
    "              \"HOUR_APPR_PROCESS_START\",\n",
    "              \"NAME_CONTRACT_TYPE_Cash loans\",\n",
    "              \"NAME_CONTRACT_TYPE_Revolving loans\",\n",
    "              \"NAME_TYPE_SUITE_Children\",\n",
    "              \"NAME_TYPE_SUITE_Family\",\n",
    "              \"NAME_TYPE_SUITE_Group of people\",\n",
    "              \"NAME_TYPE_SUITE_Other_A\",\n",
    "              \"NAME_TYPE_SUITE_Other_B\",\n",
    "              \"NAME_TYPE_SUITE_Spouse, partner\",\n",
    "              \"NAME_TYPE_SUITE_Unaccompanied\",\n",
    "              \"WEEKDAY_APPR_PROCESS_START_FRIDAY\",\n",
    "              \"WEEKDAY_APPR_PROCESS_START_MONDAY\",\n",
    "              \"WEEKDAY_APPR_PROCESS_START_SATURDAY\",\n",
    "              \"WEEKDAY_APPR_PROCESS_START_SUNDAY\",\n",
    "              \"WEEKDAY_APPR_PROCESS_START_THURSDAY\",\n",
    "              \"WEEKDAY_APPR_PROCESS_START_TUESDAY\",\n",
    "              \"WEEKDAY_APPR_PROCESS_START_WEDNESDAY\"]\n",
    "\n",
    "previous_application[\"SYNTHETIC_TARGET\"] = clf.predict_proba(scale.fit_transform(impute.fit_transform(prev_temp[dummy_cols])))[:,1]\n",
    "previous_application[\"DAYS_FIRST_DRAWING_SENTINEL\"] = (previous_application[\"DAYS_FIRST_DRAWING\"] == 365243).astype(int)\n",
    "previous_application[\"DAYS_FIRST_DUE_SENTINEL\"] = (previous_application[\"DAYS_FIRST_DUE\"] == 365243).astype(int)\n",
    "previous_application[\"DAYS_LAST_DUE_1ST_VERSION_SENTINEL\"] = (previous_application[\"DAYS_LAST_DUE_1ST_VERSION\"] == 365243).astype(int)\n",
    "previous_application[\"DAYS_LAST_DUE_SENTINEL\"] = (previous_application[\"DAYS_LAST_DUE\"] == 365243).astype(int)\n",
    "previous_application[\"DAYS_TERMINATION_SENTINEL\"] = (previous_application[\"DAYS_TERMINATION\"] == 365243).astype(int)\n",
    "\n",
    "previous_agg = previous_application.groupby(\"SK_ID_CURR\").apply(previous_agg_func).reset_index()\n",
    "\n",
    "previous_agg.to_csv(path + \"previous_agg.csv\", index=False, header=True)\n",
    "del prev_temp, previous_application, previous_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bureau Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25.5 ms\n"
     ]
    }
   ],
   "source": [
    "def bureau_balance_agg_func(g):\n",
    "    mask6 = g[\"MONTHS_BALANCE\"] >= -6\n",
    "    mask12 = g[\"MONTHS_BALANCE\"] >= -12\n",
    "    closed = g[\"STATUS\"] == \"C\"\n",
    "\n",
    "    d = {\n",
    "        \"WORST_DQ_BUREAU_BALANCE_6M\": np.nanmax(g[\"STATUS\"].apply(lambda x: 0 if x == \"C\" else int(x)).where(mask6)), \n",
    "        \"WORST_DQ_BUREAU_BALANCE_12M\": np.nanmax(g[\"STATUS\"].apply(lambda x: 0 if x == \"C\" else int(x)).where(mask12)), \n",
    "        \"LEN_BUREAU_BALANCE\": np.nansum(~closed), \n",
    "        \"SUM_CLOSED_BUREAU_BALANCE\": np.nansum(closed), \n",
    "        \"SUM_CURRENT_BUREAU_BALANCE\": np.nansum(g[\"STATUS\"] == \"0\"), \n",
    "        \"SUM_DQ_BUREAU_BALANCE\": np.nansum(g[\"STATUS\"].isin([\"1\", \"2\", \"3\", \"3\", \"4\", \"5\"])),\n",
    "        \"WORST_DQ_BUREAU_BALANCE\": np.nanmax(g[\"STATUS\"].apply(lambda x: 0 if x == \"C\" else int(x))), \n",
    "        \"AVG_MONTHS_BALANCE_BUREAU_BALANCE\": np.nansum(abs(g[\"MONTHS_BALANCE\"]).where(~closed)) / np.nansum(~closed), \n",
    "        \"MIN_MONTHS_BALANCE_BUREAU_BALANCE\": np.nanmin(g[\"MONTHS_BALANCE\"].where(~closed)), \n",
    "        \"MAX_MONTHS_BALANCE_BUREAU_BALANCE\": np.nanmax(g[\"MONTHS_BALANCE\"].where(~closed)), \n",
    "    }\n",
    "\n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance = pd.read_csv(path + \"bureau_balance.csv\")\n",
    "\n",
    "bureau_balance[\"STATUS\"] = bureau_balance[\"STATUS\"].where(lambda x: x != \"X\").fillna(\"0\")\n",
    "\n",
    "bureau_balance_agg = bureau_balance.groupby(\"SK_ID_BUREAU\").apply(bureau_balance_agg_func).reset_index()\n",
    "bureau_balance_agg.to_csv(path + \"bureau_balance_agg.csv\", index=False, header=True)\n",
    "del bureau_balance, bureau_balance_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bureau\n",
    "\n",
    "This is dependent on `bureau_balance_agg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 433 ms\n"
     ]
    }
   ],
   "source": [
    "def bureau_agg_func(g):\n",
    "    mask3 = g[\"DAYS_CREDIT_UPDATE\"] >= -90\n",
    "    mask6 = g[\"DAYS_CREDIT_UPDATE\"] >= -180\n",
    "    mask12 = g[\"DAYS_CREDIT_UPDATE\"] >= -360\n",
    "    mask24 = g[\"DAYS_CREDIT_UPDATE\"] >= -720\n",
    "    active = g[\"CREDIT_ACTIVE\"] == \"Active\"\n",
    "    cc = g[\"CREDIT_TYPE\"] == \"Credit card\"\n",
    "    \n",
    "    d = {\n",
    "        \"SUM_AMT_CREDIT_SUM_DEBT_DIV_DAYS_CREDIT_ENDDATE_ACTIVE_12M\": np.nansum((g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"DAYS_CREDIT_ENDDATE\"]).where(active & mask12)),\n",
    "        \"SUM_CC_DEBT_6M\": np.nansum(g[\"AMT_CREDIT_SUM_DEBT\"].where(cc & mask6)), \n",
    "        \"SUM_CC_DEBT_12M\": np.nansum(g[\"AMT_CREDIT_SUM_DEBT\"].where(cc & mask12)), \n",
    "        \"MAX_WORST_DQ_BUREAU_BALANCE_6M\": np.nanmax(g[\"WORST_DQ_BUREAU_BALANCE_6M\"].where(mask6)), \n",
    "        \"MAX_WORST_DQ_BUREAU_BALANCE_12M\": np.nanmax(g[\"WORST_DQ_BUREAU_BALANCE_12M\"].where(mask12)), \n",
    "        \"MAX_BUREAU_UTILIZATION_6M\": np.nanmax((g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"AMT_CREDIT_SUM\"]).where(mask6)), \n",
    "        \"MAX_BUREAU_UTILIZATION_12M\": np.nanmax((g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"AMT_CREDIT_SUM\"]).where(mask12)), \n",
    "        \"COUNT_ACTIVE_6M\": np.nansum((g[\"CREDIT_ACTIVE\"] == \"Active\").where(active & mask6)), \n",
    "        \"COUNT_ACTIVE_12M\": np.nansum((g[\"CREDIT_ACTIVE\"] == \"Active\").where(active & mask12)), \n",
    "        \"COUNT_ACTIVE_24M\": np.nansum((g[\"CREDIT_ACTIVE\"] == \"Active\").where(active & mask24)), \n",
    "        \"DAYS_REMAINING_ACTIVE\": np.nansum(g[\"DAYS_CREDIT_ENDDATE\"].where(active)), \n",
    "        \"MAX_CREDIT_DAY_OVERDUE_6M\": np.nanmax(g[\"CREDIT_DAY_OVERDUE\"].where(mask6)), \n",
    "        \"MAX_CREDIT_DAY_OVERDUE_DIFF_6M_12M\": np.nanmax(g[\"CREDIT_DAY_OVERDUE\"].where(mask6)) - np.nanmax(g[\"CREDIT_DAY_OVERDUE\"].where(mask6 ^ mask12)), \n",
    "        \"BUREAU_UTILIZATION_DIFF_6M_12M\": np.nanmean((g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"AMT_CREDIT_SUM_LIMIT\"]).where(active & mask6)) - np.nanmean((g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"AMT_CREDIT_SUM_LIMIT\"]).where(active & (mask6 ^ mask12))), \n",
    "        \"BUREAU_UTILIZATION_DIFF_12M_24M\": np.nanmean((g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"AMT_CREDIT_SUM_LIMIT\"]).where(active & mask12)) - np.nanmean((g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"AMT_CREDIT_SUM_LIMIT\"]).where(active & (mask6 ^ mask24))), \n",
    "        \"BUREAU_SUM_DEBT_DIFF_6M_12M\": np.nansum(g[\"AMT_CREDIT_SUM_DEBT\"].where(active & mask6)) - np.nansum(g[\"AMT_CREDIT_SUM_DEBT\"].where(active & (mask6 ^ mask12))),\n",
    "        \"BUREAU_SUM_DEBT_DIFF_12M_24M\": np.nansum(g[\"AMT_CREDIT_SUM_DEBT\"].where(active & mask6)) - np.nansum(g[\"AMT_CREDIT_SUM_DEBT\"].where(active & (mask6 ^ mask12))),         \n",
    "        \"MAX_CNT_CREDIT_PROLONG\": np.nanmax(g[\"CNT_CREDIT_PROLONG\"]), \n",
    "        \"AVG_LEN_BUREAU_BALANCE\": np.nanmean(g[\"LEN_BUREAU_BALANCE\"]), \n",
    "        \"PROP_CURRENT\": np.nansum(g[\"SUM_CURRENT_BUREAU_BALANCE\"]) / np.nansum(g[\"LEN_BUREAU_BALANCE\"]), \n",
    "        \"PROP_CLOSED\": np.nansum(g[\"SUM_CLOSED_BUREAU_BALANCE\"]) / np.nansum(g[\"LEN_BUREAU_BALANCE\"]), \n",
    "        \"PROP_CURRENT_WEIGHTED\": np.nansum(g[\"SUM_CURRENT_BUREAU_BALANCE\"]) / np.nansum(g[\"LEN_BUREAU_BALANCE\"]) / np.nansum(g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"MAX_AVG_MONTHS_BALANCE_BUREAU_BALANCE\": np.nanmax(g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"MIN_AVG_MONTHS_BALANCE_BUREAU_BALANCE\": np.nanmin(g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"RANGE_AVG_MONTHS_BALANCE_BUREAU_BALANCE\": np.nanmax(g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]) - np.nanmin(g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"SUM_SUM_CURRENT_BUREAU_BALANCE\": np.nansum(g[\"SUM_CURRENT_BUREAU_BALANCE\"]), \n",
    "        \"AVG_PROP_CURRENT\": np.nanmean(g[\"SUM_CURRENT_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"]), \n",
    "        \"AVG_PROP_DQ\": np.nanmean(g[\"SUM_DQ_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"]), \n",
    "        \"MAX_PROP_DQ\": np.nanmax(g[\"SUM_DQ_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"]),\n",
    "        \"AVG_PROP_CURRENT_WEIGHTED\": np.nanmean(g[\"SUM_CURRENT_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"MIN_PROP_CURRENT_WEIGHTED\": np.nanmin(g[\"SUM_CURRENT_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"AVG_PROP_DQ_WEIGHTED\": np.nanmean(g[\"SUM_DQ_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"MAX_PROP_DQ_WEIGHTED\": np.nanmax(g[\"SUM_DQ_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"AVG_PROP_CURRENT_WEIGHTED_AMT\": np.nanmean(g[\"AMT_CREDIT_SUM\"] * g[\"SUM_CURRENT_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"MIN_PROP_CURRENT_WEIGHTED_AMT\": np.nanmin(g[\"AMT_CREDIT_SUM\"] * g[\"SUM_CURRENT_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"AVG_PROP_DQ_WEIGHTED_AMT\": np.nanmean(g[\"AMT_CREDIT_SUM\"] * g[\"SUM_DQ_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"MAX_PROP_DQ_WEIGHTED_AMT\": np.nanmax(g[\"AMT_CREDIT_SUM\"] * g[\"SUM_DQ_BUREAU_BALANCE\"] / g[\"LEN_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]),          \n",
    "        \"AVG_WORST_DQ_BUREAU_BALANCE\": np.nanmean(g[\"WORST_DQ_BUREAU_BALANCE\"]), \n",
    "        \"MAX_WORST_DQ_BUREAU_BALANCE_WEIGHTED\": np.nanmax(g[\"WORST_DQ_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"AVG_WORST_DQ_BUREAU_BALANCE_WEIGHTED\": np.nanmean(g[\"WORST_DQ_BUREAU_BALANCE\"] / g[\"AVG_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"TOTAL_AMT_CREDIT_SUM_POS_DAYS\": np.nansum(g[\"AMT_CREDIT_SUM\"].where(g[\"DAYS_CREDIT_ENDDATE\"] > 0)),\n",
    "        \"SUM_DAYS_CREDIT_ENDDATE_POS_DAYS\": np.nansum(g[\"DAYS_CREDIT_ENDDATE\"].where(g[\"DAYS_CREDIT_ENDDATE\"] > 0)), \n",
    "        \"MAX_LEN_BUREAU_BALANCE\": np.nanmax(g[\"LEN_BUREAU_BALANCE\"]), \n",
    "        \"SUM_LEN_BUREAU_BALANCE\": np.nanmax(g[\"LEN_BUREAU_BALANCE\"]), \n",
    "        \"MIN_MIN_MONTHS_BALANCE_BUREAU_BALANCE\": np.nanmin(g[\"MIN_MONTHS_BALANCE_BUREAU_BALANCE\"]), \n",
    "        \"MIN_DAYS_CREDIT_ENDDATE\": np.nanmin(g[\"DAYS_CREDIT_ENDDATE\"]), \n",
    "        \"MAX_DAYS_CREDIT_ENDDATE\": np.nanmax(g[\"DAYS_CREDIT_ENDDATE\"]), \n",
    "        \"SUM_DAYS_CREDIT_ENDDATE\": np.nansum(g[\"DAYS_CREDIT_ENDDATE\"]), \n",
    "        \"SUM_NULL_DAYS_ENDDATE_FACT\": np.nansum(g[\"DAYS_ENDDATE_FACT\"].isnull()), \n",
    "        \"COUNT_BUREAU_RECORDS\": len(g), \n",
    "        \"COUNT_ACTIVE\": np.nansum(active), \n",
    "        \"MAX_CREDIT_DAY_OVERDUE_WEIGHTED\": np.nanmax(g[\"CREDIT_DAY_OVERDUE\"] / abs(g[\"DAYS_CREDIT_UPDATE\"])), \n",
    "        \"SUM_CREDIT_DAY_OVERDUE_WEIGHTED\": np.nansum(g[\"CREDIT_DAY_OVERDUE\"] / abs(g[\"DAYS_CREDIT_UPDATE\"])), \n",
    "        \"MAX_CREDIT_DAY_OVERDUE\": np.nanmax(g[\"CREDIT_DAY_OVERDUE\"]), \n",
    "        \"SUM_CREDIT_DAY_OVERDUE\": np.nansum(g[\"CREDIT_DAY_OVERDUE\"]), \n",
    "        \"DAYS_SINCE_APPLIED\": - np.nanmax(g[\"DAYS_CREDIT\"]), \n",
    "        \"SUM_INVERSE_DAYS_CREDIT\": - np.nansum(1 / g[\"DAYS_CREDIT\"]), \n",
    "        \"MAX_AMT_CREDIT_MAX_OVERDUE_WEIGHTED\": np.nanmax(g[\"AMT_CREDIT_MAX_OVERDUE\"] / abs(g[\"DAYS_CREDIT_UPDATE\"])), \n",
    "        \"SUM_AMT_CREDIT_MAX_OVERDUE_WEIGHTED\": np.nansum(g[\"AMT_CREDIT_MAX_OVERDUE\"] / abs(g[\"DAYS_CREDIT_UPDATE\"])), \n",
    "        \"MAX_AMT_CREDIT_MAX_OVERDUE\": np.nanmax(g[\"AMT_CREDIT_MAX_OVERDUE\"]), \n",
    "        \"SUM_AMT_CREDIT_MAX_OVERDUE\": np.nansum(g[\"AMT_CREDIT_MAX_OVERDUE\"]), \n",
    "        \"SUM_CNT_CREDIT_PROLONG\": np.nansum(g[\"CNT_CREDIT_PROLONG\"]), \n",
    "        \"SUM_AMT_CREDIT_SUM_DEBT_WEIGHTED\": np.nansum(g[\"AMT_CREDIT_SUM_DEBT\"] / abs(g[\"DAYS_CREDIT_UPDATE\"])), \n",
    "        \"SUM_AMT_CREDIT_SUM_DEBT\": np.nansum(g[\"AMT_CREDIT_SUM_DEBT\"]),\n",
    "        \"BUREAU_UTILIZATION_AVG\": np.nanmean(g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"AMT_CREDIT_SUM_LIMIT\"]), \n",
    "        \"BUREAU_UTILIZATION_MAX\": np.nanmax(g[\"AMT_CREDIT_SUM_DEBT\"] / g[\"AMT_CREDIT_SUM_LIMIT\"]), \n",
    "        \"BUREAU_PROP_SUM_OVERDUE_AVG\": np.nanmean(g[\"AMT_CREDIT_SUM_OVERDUE\"] / g[\"AMT_CREDIT_SUM_DEBT\"]), \n",
    "        \"BUREAU_PROP_MAX_OVERDUE_AVG\": np.nanmean(g[\"AMT_CREDIT_MAX_OVERDUE\"] / g[\"AMT_CREDIT_SUM_DEBT\"]), \n",
    "        \"MAX_DAYS_CREDIT_UPDATE\": np.nanmax(g[\"DAYS_CREDIT_UPDATE\"]), \n",
    "        \"RANGE_DAYS_CREDIT_UPDATE\": np.nanmax(g[\"DAYS_CREDIT_UPDATE\"]) - np.nanmin(g[\"DAYS_CREDIT_UPDATE\"]), \n",
    "        \"DAYS_CREDIT_RANGE\": np.nanmax(g[\"DAYS_CREDIT\"]) - np.nanmin(g[\"DAYS_CREDIT\"]), \n",
    "        \"TOTAL_AMT_CREDIT_SUM_WEIGHTED\": np.nansum(g[\"AMT_CREDIT_SUM\"] / abs(g[\"DAYS_CREDIT_UPDATE\"])),\n",
    "        \"TOTAL_AMT_CREDIT_SUM\": np.nansum(g[\"AMT_CREDIT_SUM\"]),\n",
    "        \"COUNT_CREDIT_CARD\": np.nansum(g[\"CREDIT_TYPE\"] == \"Credit card\"), \n",
    "        \"COUNT_CAR_LOAN\": np.nansum(g[\"CREDIT_TYPE\"] == \"Car loan\"), \n",
    "        \"COUNT_MORTGAGE\": np.nansum(g[\"CREDIT_TYPE\"] == \"Mortgage\"), \n",
    "        \"SUM_AMT_ANNUITY\": np.nansum(g[\"AMT_ANNUITY\"]), \n",
    "    }\n",
    "    \n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4h 9min 27s\n"
     ]
    }
   ],
   "source": [
    "bureau = pd.read_csv(path + \"bureau.csv\")\n",
    "bureau_balance_agg = pd.read_csv(path + \"bureau_balance_agg.csv\")\n",
    "\n",
    "bureau_joined = pd.merge(bureau, \n",
    "                         bureau_balance_agg, \n",
    "                         how=\"left\", \n",
    "                         on=\"SK_ID_BUREAU\")\n",
    "\n",
    "bureau_agg = bureau_joined.groupby(\"SK_ID_CURR\").apply(bureau_agg_func).reset_index()\n",
    "bureau_agg.to_csv(path + \"bureau_agg.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 49 ms\n"
     ]
    }
   ],
   "source": [
    "def credit_card_agg_func(g):\n",
    "    mask3 = g[\"MONTHS_BALANCE\"] >= -3\n",
    "    mask6 = g[\"MONTHS_BALANCE\"] >= -6\n",
    "    mask12 = g[\"MONTHS_BALANCE\"] >= -12\n",
    "    active = g[\"NAME_CONTRACT_STATUS\"] == \"Active\"\n",
    "    overdue = g[\"SK_DPD\"] > 0\n",
    "    \n",
    "    d = {\n",
    "        \"MAX_CREDIT_CARD_INST_AMT_PAST_DUE_6M\": np.nanmax(g[\"AMT_INST_MIN_REGULARITY\"].where(overdue & mask6)), \n",
    "        \"MIN_CREDIT_CARD_INST_AMT_PAST_DUE_12M\": np.nanmin(g[\"AMT_INST_MIN_REGULARITY\"].where(overdue & mask12)), \n",
    "        \"SUM_CNT_DRAWINGS_ATM_CURRENT_6M\": np.nansum(g[\"CNT_DRAWINGS_ATM_CURRENT\"].where(mask6)), \n",
    "        \"SUM_AMT_DRAWINGS_ATM_CURRENT_6M\": np.nansum(g[\"AMT_DRAWINGS_ATM_CURRENT\"].where(mask6)), \n",
    "        \"MAX_AMT_DRAWINGS_ATM_CURRENT_6M\": np.nanmax(g[\"AMT_DRAWINGS_ATM_CURRENT\"].where(mask6)), \n",
    "        \"MAX_CNT_DRAWINGS_ATM_CURRENT_6M\": np.nanmax(g[\"CNT_DRAWINGS_ATM_CURRENT\"].where(mask6)), \n",
    "        \"MAX_AMT_RECEIVABLE_DIV_AMT_RECEIVABLE_PRINCIPAL_6M\": np.nanmax((g[\"AMT_RECIVABLE\"] / g[\"AMT_RECEIVABLE_PRINCIPAL\"]).where(mask6)), \n",
    "        \"MAX_UTILIZATION_6M\": np.nanmax((g[\"AMT_BALANCE\"] / g[\"AMT_CREDIT_LIMIT_ACTUAL\"]).where(mask6)),\n",
    "        \"MAX_CREDIT_CARD_SK_DPD_6M\": np.nanmax(g[\"SK_DPD\"].where(mask6)), \n",
    "        \"MAX_CREDIT_CARD_SK_DPD_12M\": np.nanmax(g[\"SK_DPD\"].where(mask12)),\n",
    "        \"MAX_AMT_DRAWINGS_CURRENT_6M\": np.nanmax(g[\"AMT_DRAWINGS_CURRENT\"].where(mask6)), \n",
    "        \"MAX_AMT_DRAWINGS_CURRENT_12M\": np.nanmax(g[\"AMT_DRAWINGS_CURRENT\"].where(mask12)), \n",
    "        \"MAX_AMT_INST_MIN_REGULARITY_6M\": np.nanmax(g[\"AMT_INST_MIN_REGULARITY\"].where(mask6)), \n",
    "        \"MAX_AMT_INST_MIN_REGULARITY_12M\": np.nanmax(g[\"AMT_INST_MIN_REGULARITY\"].where(mask12)), \n",
    "        \"MAX_CNT_DRAWINGS_POS_CURRENT_6M\": np.nanmax(g[\"CNT_DRAWINGS_POS_CURRENT\"].where(mask6)), \n",
    "        \"MAX_CNT_DRAWINGS_POS_CURRENT_12M\": np.nanmax(g[\"CNT_DRAWINGS_POS_CURRENT\"].where(mask12)), \n",
    "        \"SUM_CC_PAYMENT_DIFF_12M\": np.nansum((g[\"AMT_PAYMENT_TOTAL_CURRENT\"] - g[\"AMT_INST_MIN_REGULARITY\"]).where(mask12)),\n",
    "        \"DIFF_AVG_BALANCE_6M_12M\": np.nanmean(g[\"AMT_BALANCE\"].where(mask6)) - np.nanmean(g[\"AMT_BALANCE\"].where(mask6 ^ mask12)),\n",
    "        \"AVG_BALANCE_6M\": np.nanmean(g[\"AMT_BALANCE\"].where(mask6)),\n",
    "        \"AVG_UTILIZATION_6M\": np.nanmean((g[\"AMT_BALANCE\"] / g[\"AMT_CREDIT_LIMIT_ACTUAL\"]).where(mask6)),\n",
    "        \"AVG_BALANCE\": np.nanmean(g[\"AMT_BALANCE\"]), \n",
    "        \"MAX_BALANCE\": np.nanmax(g[\"AMT_BALANCE\"]), \n",
    "        \"SUM_BALANCE\": np.nansum(g[\"AMT_BALANCE\"]), \n",
    "        \"MAX_MONTHS_BALANCE\": np.nanmax(abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"MIN_MONTHS_BALANCE\": np.nanmin(abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"RANGE_MONTHS_BALANCE\": np.nanmax(g[\"MONTHS_BALANCE\"]) - np.nanmin(g[\"MONTHS_BALANCE\"]), \n",
    "        \"AVG_UTILIZATION\": np.nanmean(g[\"AMT_BALANCE\"] / g[\"AMT_CREDIT_LIMIT_ACTUAL\"]), \n",
    "        \"MAX_UTILIZATION\": np.nanmax(g[\"AMT_BALANCE\"] / g[\"AMT_CREDIT_LIMIT_ACTUAL\"]), \n",
    "        \"AVG_BALANCE_WEIGHTED\": np.nanmean(g[\"AMT_BALANCE\"] / abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"MAX_BALANCE_WEIGHTED\": np.nanmax(g[\"AMT_BALANCE\"] / abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"SUM_BALANCE_WEIGHTED\": np.nansum(g[\"AMT_BALANCE\"] / abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"AVG_UTILIZATION_WEIGHTED\": np.nanmean(g[\"AMT_BALANCE\"] / g[\"AMT_CREDIT_LIMIT_ACTUAL\"] / abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"MAX_UTILIZATION_WEIGHTED\": np.nanmax(g[\"AMT_BALANCE\"] / g[\"AMT_CREDIT_LIMIT_ACTUAL\"] / abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"MAX_DPD_WEIGHTED\": np.nanmax(g[\"SK_DPD\"] / abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"MAX_DPD_DEF_WEIGHTED\": np.nanmax(g[\"SK_DPD_DEF\"] / abs(g[\"MONTHS_BALANCE\"])), \n",
    "        \"SUM_CNT_DRAWINGS_CURRENT\": np.nansum(g[\"CNT_DRAWINGS_CURRENT\"]), \n",
    "        \"AVG_CNT_DRAWINGS_CURRENT\": np.nanmean(g[\"CNT_DRAWINGS_CURRENT\"]), \n",
    "        \"MAX_CNT_DRAWINGS_CURRENT\": np.nanmax(g[\"CNT_DRAWINGS_CURRENT\"]), \n",
    "        \"SUM_AMT_DRAWINGS_CURRENT\": np.nansum(g[\"AMT_DRAWINGS_CURRENT\"]), \n",
    "        \"AVG_AMT_DRAWINGS_CURRENT\": np.nanmean(g[\"AMT_DRAWINGS_CURRENT\"]), \n",
    "        \"MAX_AMT_DRAWINGS_CURRENT\": np.nanmax(g[\"AMT_DRAWINGS_CURRENT\"]), \n",
    "        \"MIN_AMT_PAYMENT_CURRENT_DIV_AMT_INST_MIN_REGULARITY\": np.nanmin(g[\"AMT_PAYMENT_CURRENT\"] / g[\"AMT_INST_MIN_REGULARITY\"]), \n",
    "        \"AVG_AMT_PAYMENT_CURRENT_DIV_AMT_INST_MIN_REGULARITY\": np.nanmean(g[\"AMT_PAYMENT_CURRENT\"] / g[\"AMT_INST_MIN_REGULARITY\"]), \n",
    "        \"MAX_AMT_PAYMENT_CURRENT_DIV_AMT_INST_MIN_REGULARITY\": np.nanmax(g[\"AMT_PAYMENT_CURRENT\"] / g[\"AMT_INST_MIN_REGULARITY\"]), \n",
    "    }\n",
    "    \n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 34min 6s\n"
     ]
    }
   ],
   "source": [
    "credit_card = pd.read_csv(path + \"credit_card_balance.csv\")\n",
    "\n",
    "credit_card_agg = credit_card.groupby(\"SK_ID_CURR\").apply(credit_card_agg_func).reset_index()\n",
    "credit_card_agg.to_csv(path + \"credit_card_agg.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installment_agg_func(g):\n",
    "    mask6 = g[\"DAYS_ENTRY_PAYMENT\"] >= -180\n",
    "    mask12 = g[\"DAYS_ENTRY_PAYMENT\"] >= -360\n",
    "    \n",
    "    d = {\n",
    "        \"MAX_UNDERPAYMENT_6M\": np.nanmax((g[\"AMT_INSTALMENT\"] - g[\"AMT_PAYMENT\"]).where(mask6)), \n",
    "        \"MAX_UNDERPAYMENT_12M\": np.nanmax((g[\"AMT_INSTALMENT\"] - g[\"AMT_PAYMENT\"]).where(mask12)), \n",
    "        \"SUM_PAYMENT_6M\": np.nansum(g[\"AMT_PAYMENT\"].where(mask6)), \n",
    "        \"SUM_PAYMENT_DIFF_6M_12M\": np.nansum(g[\"AMT_PAYMENT\"].where(mask6)) - np.nansum(g[\"AMT_PAYMENT\"].where(mask6 ^ mask12)), \n",
    "        \"MAX_AMT_INSTALMENT_6M\": np.nanmax(g[\"AMT_INSTALMENT\"].where(mask6)), \n",
    "        \"MIN_AMT_INSTALMENT_6M\": np.nanmin(g[\"AMT_INSTALMENT\"].where(mask6)), \n",
    "        \"MAX_DAYS_ENTRY_PAYMENT_DIFF_DAYS_INSTALMENT_12M\": np.nanmax((g[\"DAYS_ENTRY_PAYMENT\"] - g[\"DAYS_INSTALMENT\"])), \n",
    "        \"MIN_DAYS_ENTRY_PAYMENT_DIFF_DAYS_INSTALMENT_12M\": np.nanmin((g[\"DAYS_ENTRY_PAYMENT\"] - g[\"DAYS_INSTALMENT\"])), \n",
    "        \"SUM_UNDERPAYMENT_12M\": np.nansum((g[\"AMT_INSTALMENT\"] - g[\"AMT_PAYMENT\"]).where(mask12)), \n",
    "        \"SUM_UNDERPAYMENT_6M\": np.nansum((g[\"AMT_INSTALMENT\"] - g[\"AMT_PAYMENT\"]).where(mask6)), \n",
    "        \"MAX_PAYMENT_SIZE_6M\": np.nanmax(g[\"AMT_PAYMENT\"].where(mask6)), \n",
    "        \"MAX_PAYMENT_SIZE_12M\": np.nanmax(g[\"AMT_PAYMENT\"].where(mask12)), \n",
    "        \"MIN_PAYMENT_SIZE_6M\": np.nanmin(g[\"AMT_PAYMENT\"].where(mask6)),\n",
    "        \"MAX_ABS_DAYS_INSTALMENT\": np.nanmax(abs(g[\"DAYS_INSTALMENT\"])), \n",
    "        \"COUNT_UNDERPAYMENT\": np.nansum(g[\"AMT_PAYMENT\"] / g[\"AMT_INSTALMENT\"] < 0.5), \n",
    "        \"SUM_UNDERPAYMENT\": np.nansum(g[\"AMT_INSTALMENT\"] - g[\"AMT_PAYMENT\"]), \n",
    "        \"SUM_UNDERPAYMENT_WEIGHTED\": np.nansum((g[\"AMT_INSTALMENT\"] - g[\"AMT_PAYMENT\"]) / abs(g[\"DAYS_ENTRY_PAYMENT\"])), \n",
    "        \"MAX_UNDERPAYMENT\": np.nanmax(g[\"AMT_INSTALMENT\"] - g[\"AMT_PAYMENT\"]), \n",
    "        \"AVG_PAYMENT_SIZE_WEIGHTED\": np.nanmean(g[\"AMT_PAYMENT\"] / abs(g[\"DAYS_ENTRY_PAYMENT\"])), \n",
    "        \"AVG_PAYMENT_SIZE\": np.nanmean(g[\"AMT_PAYMENT\"]), \n",
    "        \"MAX_PAYMENT_SIZE_WEIGHTED\": np.nanmax(g[\"AMT_PAYMENT\"] / abs(g[\"DAYS_ENTRY_PAYMENT\"])), \n",
    "        \"MAX_PAYMENT_SIZE\": np.nanmax(g[\"AMT_PAYMENT\"]), \n",
    "        \"MIN_PAYMENT_SIZE_WEIGHTED\": np.nanmin(g[\"AMT_PAYMENT\"] / abs(g[\"DAYS_ENTRY_PAYMENT\"])), \n",
    "        \"MIN_PAYMENT_SIZE\": np.nanmin(g[\"AMT_PAYMENT\"]),\n",
    "        \"SUM_PAYMENT_WEIGHTED\": np.nansum(g[\"AMT_PAYMENT\"] / abs(g[\"DAYS_ENTRY_PAYMENT\"])), \n",
    "        \"SUM_PAYMENT\": np.nansum(g[\"AMT_PAYMENT\"]),\n",
    "        \"SUM_DAYS_ENTRY_PAYMENT_GT_DAYS_INSTALMENT\": np.nansum(g[\"DAYS_ENTRY_PAYMENT\"] > g[\"DAYS_INSTALMENT\"]), \n",
    "        \"MAX_DAYS_ENTRY_PAYMENT\": np.nanmax(g[\"DAYS_ENTRY_PAYMENT\"]), \n",
    "        \"MIN_DAYS_ENTRY_PAYMENT\": np.nanmin(g[\"DAYS_ENTRY_PAYMENT\"]), \n",
    "        \"RANGE_DAYS_ENTRY_PAYMENT\": np.nanmax(g[\"DAYS_ENTRY_PAYMENT\"]) - np.nanmin(g[\"DAYS_ENTRY_PAYMENT\"]), \n",
    "    }\n",
    "    \n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments = pd.read_csv(path + \"installments_payments.csv\")\n",
    "\n",
    "installment_agg = installments.groupby(\"SK_ID_CURR\").apply(installment_agg_func).reset_index()\n",
    "installment_agg.to_csv(path + \"installment_agg.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point of Sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cash_agg_func(g):\n",
    "    mask3 = g[\"MONTHS_BALANCE\"] >= -3\n",
    "    mask6 = g[\"MONTHS_BALANCE\"] >= -6\n",
    "    mask12 = g[\"MONTHS_BALANCE\"] >= -12\n",
    "    overdue = g[\"SK_DPD\"] > 0\n",
    "    \n",
    "    d = {\n",
    "        \"MIN_CNT_INSTALMENT_FUTURE_6M\": np.nanmin(g[\"CNT_INSTALMENT_FUTURE\"].where(mask6)), \n",
    "        \"MAX_CNT_INSTALMENT_FUTURE_6M\": np.nanmax(g[\"CNT_INSTALMENT_FUTURE\"].where(mask6)), \n",
    "        \"MAX_CNT_INSTALMENT_FUTURE_PROD_SK_DPD_12M\": np.nanmax((g[\"CNT_INSTALMENT_FUTURE\"] * g[\"SK_DPD\"]).where(mask12)), \n",
    "        \"MAX_POS_DPD\": np.nanmax(g[\"SK_DPD\"]), \n",
    "        \"MAX_POS_DPD_DEF\": np.nanmax(g[\"SK_DPD_DEF\"]), \n",
    "        \"NUM_POS_CASH\": g[\"SK_ID_PREV\"].nunique(), \n",
    "    }\n",
    "    \n",
    "    return pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash = pd.read_csv(path + \"POS_CASH_balance.csv\")\n",
    "\n",
    "pos_cash_agg = pos_cash.groupby(\"SK_ID_CURR\").apply(pos_cash_agg_func).reset_index()\n",
    "pos_cash_agg.to_csv(path + \"pos_cash_agg.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 840 µs\n"
     ]
    }
   ],
   "source": [
    "train_or_test = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55 s\n"
     ]
    }
   ],
   "source": [
    "application = pd.read_csv(path + \"application_\" + train_or_test + \".csv\")\n",
    "previous_agg = pd.read_csv(path + \"previous_agg.csv\")\n",
    "# bureau_balance_agg should already be joined with bureau_agg\n",
    "bureau_agg = pd.read_csv(path + \"bureau_agg.csv\")\n",
    "credit_card_agg = pd.read_csv(path + \"credit_card_agg.csv\")\n",
    "installment_agg = pd.read_csv(path + \"installment_agg.csv\")\n",
    "pos_cash_agg = pd.read_csv(path + \"pos_cash_agg.csv\")\n",
    "\n",
    "df = pd.merge(application, previous_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "df = pd.merge(df, bureau_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "df = pd.merge(df, credit_card_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "df = pd.merge(df, installment_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "df = pd.merge(df, pos_cash_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "del previous_agg, bureau_agg, credit_card_agg, installment_agg, pos_cash_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "df[\"TOTAL_AMT_CREDIT_SUM_DIV_SUM_DAYS_CREDIT_ENDDATE\"] = df[\"TOTAL_AMT_CREDIT_SUM\"] / df[\"SUM_DAYS_CREDIT_ENDDATE\"]\n",
    "df[\"TOTAL_AMT_CREDIT_SUM_POS_DAYS_DIV_SUM_DAYS_CREDIT_ENDDATE_POS_DAYS\"] = df[\"TOTAL_AMT_CREDIT_SUM_POS_DAYS\"] / df[\"SUM_DAYS_CREDIT_ENDDATE_POS_DAYS\"]\n",
    "df[\"MAX_ABS_DAYS_INSTALMENT_DIV_DAYS_BIRTH\"] = df[\"MAX_ABS_DAYS_INSTALMENT\"] / df[\"DAYS_BIRTH\"]\n",
    "df[\"FLAG_OWN_CAR\"] = (df[\"FLAG_OWN_CAR\"] == \"Y\").astype(int)\n",
    "df[\"FLAG_OWN_REALTY\"] = (df[\"FLAG_OWN_REALTY\"] == \"Y\").astype(int)\n",
    "df[\"AMT_CREDIT_DIV_AMT_INCOME_TOTAL\"] = df[\"AMT_CREDIT\"] / df[\"AMT_INCOME_TOTAL\"]\n",
    "df[\"AMT_CREDIT_PLUS_AMT_INCOME_TOTAL\"] = df[\"AMT_CREDIT\"] + df[\"AMT_INCOME_TOTAL\"]\n",
    "df[\"AMT_CREDIT_DIV_AMT_GOODS_PRICE\"] = df[\"AMT_CREDIT\"] / df[\"AMT_GOODS_PRICE\"]\n",
    "df[\"AMT_CREDIT_DIV_SUM_PAYMENT\"] = df[\"AMT_CREDIT\"] / df[\"SUM_PAYMENT\"]\n",
    "df[\"AMT_GOODS_PRICE_DIV_AMT_INCOME_TOTAL\"] = df[\"AMT_GOODS_PRICE\"] / df[\"AMT_INCOME_TOTAL\"]\n",
    "df[\"AMT_CREDIT_DIV_AMT_ANNUITY\"] = df[\"AMT_CREDIT\"] / df[\"AMT_ANNUITY\"]\n",
    "df[\"AMT_CREDIT_DIV_AVG_PREV_REQ_AMOUNT\"] = df[\"AMT_CREDIT\"] / df[\"AVG_PREV_REQ_AMOUNT\"]\n",
    "df[\"AMT_CREDIT_DIV_MAX_PREV_REQ_AMOUNT\"] = df[\"AMT_CREDIT\"] / df[\"MAX_PREV_REQ_AMOUNT\"]\n",
    "df[\"EXT_SOURCE_PROD\"] = df[\"EXT_SOURCE_1\"] * df[\"EXT_SOURCE_2\"] * df[\"EXT_SOURCE_3\"]\n",
    "df[\"DAYS_EMPLOYED_DIV_DAYS_BIRTH\"] = df[\"DAYS_EMPLOYED\"] / df[\"DAYS_BIRTH\"]\n",
    "df[\"DAYS_EMPLOYED_PLUS_DAYS_REGISTRATION_PLUS_DAYS_LAST_PHONE_CHANGE\"] = df[\"DAYS_EMPLOYED\"] + df[\"DAYS_REGISTRATION\"] + df[\"DAYS_LAST_PHONE_CHANGE\"]\n",
    "df[\"AVG_PAYMENT_SIZE_DIV_AMT_INCOME_TOTAL\"] = df[\"AVG_PAYMENT_SIZE\"] / df[\"AMT_INCOME_TOTAL\"]\n",
    "df[\"AVG_PAYMENT_SIZE_DIV_AMT_CREDIT\"] = df[\"AVG_PAYMENT_SIZE\"] / df[\"AMT_CREDIT\"]\n",
    "df[\"AVG_PAYMENT_SIZE_DIV_AMT_ANNUITY\"] = df[\"AVG_PAYMENT_SIZE\"] / df[\"AMT_ANNUITY\"]\n",
    "df[\"DAYS_REGISTRATION_PLUS_DAYS_ID_PUBLISH\"] = df[\"DAYS_REGISTRATION\"] + df[\"DAYS_ID_PUBLISH\"]\n",
    "df[\"SUM_REFUSED_CONTRACT_DIV_SUM_APPR_CONTRACT\"] = df[\"SUM_REFUSED_CONTRACT\"] / df[\"SUM_APPR_CONTRACT\"]\n",
    "df[\"MAX_UTILIZATION_DIV_AVG_UTILIZATION\"] = df[\"MAX_UTILIZATION\"] / df[\"AVG_UTILIZATION\"]\n",
    "df[\"MAX_PREV_REQ_AMOUNT_DIV_AMT_CREDIT\"] = df[\"MAX_PREV_REQ_AMOUNT\"] / df[\"AMT_CREDIT\"]\n",
    "df[\"AMT_INCOME_TOTAL_DIV_DAYS_BIRTH\"] = df[\"AMT_INCOME_TOTAL\"] / df[\"DAYS_BIRTH\"]\n",
    "df[\"SUM_DAYS_ID_REG_PHONE\"] = df[\"DAYS_ID_PUBLISH\"] + df[\"DAYS_REGISTRATION\"] + df[\"DAYS_LAST_PHONE_CHANGE\"]\n",
    "df[\"SUM_REQ_CREDIT_YEAR\"] = df[\"AMT_REQ_CREDIT_BUREAU_HOUR\"] + df[\"AMT_REQ_CREDIT_BUREAU_DAY\"] + df[\"AMT_REQ_CREDIT_BUREAU_WEEK\"] + df[\"AMT_REQ_CREDIT_BUREAU_MON\"] + df[\"AMT_REQ_CREDIT_BUREAU_QRT\"] + df[\"AMT_REQ_CREDIT_BUREAU_YEAR\"]\n",
    "df[\"SUM_REQ_CREDIT_QRT\"] = df[\"AMT_REQ_CREDIT_BUREAU_HOUR\"] + df[\"AMT_REQ_CREDIT_BUREAU_DAY\"] + df[\"AMT_REQ_CREDIT_BUREAU_WEEK\"] + df[\"AMT_REQ_CREDIT_BUREAU_MON\"] + df[\"AMT_REQ_CREDIT_BUREAU_QRT\"]\n",
    "df[\"SUM_REQ_CREDIT_1M\"] = df[\"AMT_REQ_CREDIT_BUREAU_HOUR\"] + df[\"AMT_REQ_CREDIT_BUREAU_DAY\"] + df[\"AMT_REQ_CREDIT_BUREAU_WEEK\"] + df[\"AMT_REQ_CREDIT_BUREAU_MON\"]\n",
    "df[\"SUM_REQ_CREDIT_1M_DIV_SUM_REQ_CREDIT_QRT\"] = df[\"SUM_REQ_CREDIT_1M\"] / df[\"SUM_REQ_CREDIT_QRT\"]\n",
    "df[\"SUM_REQ_CREDIT_QRT_DIV_SUM_REQ_CREDIT_YEAR\"] = df[\"SUM_REQ_CREDIT_QRT\"] / df[\"SUM_REQ_CREDIT_YEAR\"]\n",
    "df[\"DEF_30_PLUS_60_CNT_SOCIAL_CIRCLE\"] = df[\"DEF_30_CNT_SOCIAL_CIRCLE\"] + df[\"DEF_60_CNT_SOCIAL_CIRCLE\"]\n",
    "df[\"OWN_CAR_AGE_DIV_DAYS_BIRTH\"] = df[\"OWN_CAR_AGE\"] / df[\"DAYS_BIRTH\"]\n",
    "df[\"LANDAREA_DIV_TOTALAREA_MODE\"] = df[\"LANDAREA_MODE\"] / df[\"TOTALAREA_MODE\"]\n",
    "df[\"OWN_CAR_AGE_PLUS_DAYS_BIRTH\"] = df[\"OWN_CAR_AGE\"] + df[\"DAYS_BIRTH\"]\n",
    "df[\"AMT_ANNUITY_DIV_DAYS_BIRTH\"] = df[\"AMT_ANNUITY\"] / df[\"DAYS_BIRTH\"]\n",
    "df[\"AMT_ANNUITY_DIV_DAYS_EMPLOYED\"] = df[\"AMT_ANNUITY\"] / df[\"DAYS_EMPLOYED\"]\n",
    "df[\"AMT_ANNUITY_PROD_DAYS_EMPLOYED\"] = df[\"AMT_ANNUITY\"] * df[\"DAYS_EMPLOYED\"]\n",
    "df[\"DAYS_REGISTRATION_DIV_DAYS_ID_PUBLISH\"] = df[\"DAYS_REGISTRATION\"] / df[\"DAYS_ID_PUBLISH\"]\n",
    "df[\"DAYS_REGISTRATION_DIV_DAYS_LAST_PHONE_CHANGE\"] = df[\"DAYS_REGISTRATION\"] / df[\"DAYS_LAST_PHONE_CHANGE\"]\n",
    "df[\"REGION_RATING_CLIENT_W_CITY_DIV_REGION_POPULATION_RELATIVE\"] = df[\"REGION_RATING_CLIENT_W_CITY\"] / df[\"REGION_POPULATION_RELATIVE\"]\n",
    "df[\"REGION_RATING_CLIENT_W_CITY_DIV_REGION_POPULATION_RELATIVE\"] = df[\"REGION_RATING_CLIENT_W_CITY\"] * df[\"REGION_POPULATION_RELATIVE\"]\n",
    "df[\"SUM_REG_NOT_FLAG\"] = df[\"REG_REGION_NOT_LIVE_REGION\"] + df[\"REG_REGION_NOT_WORK_REGION\"] + df[\"LIVE_REGION_NOT_WORK_REGION\"] + df[\"REG_CITY_NOT_LIVE_CITY\"] + df[\"REG_CITY_NOT_WORK_CITY\"] + df[\"LIVE_CITY_NOT_WORK_CITY\"]\n",
    "df[\"SUM_AVG_BUILD\"] = df[\"APARTMENTS_AVG\"] + df[\"BASEMENTAREA_AVG\"] + df[\"YEARS_BEGINEXPLUATATION_AVG\"] + df[\"YEARS_BUILD_AVG\"] + df[\"COMMONAREA_AVG\"] + df[\"ELEVATORS_AVG\"] + df[\"ENTRANCES_AVG\"] + df[\"FLOORSMAX_AVG\"] + df[\"FLOORSMIN_AVG\"] + df[\"LANDAREA_AVG\"] + df[\"LIVINGAPARTMENTS_AVG\"] + df[\"LIVINGAREA_AVG\"] + df[\"NONLIVINGAPARTMENTS_AVG\"] + df[\"NONLIVINGAREA_AVG\"]\n",
    "df[\"SUM_MODE_BUILD\"] = df[\"APARTMENTS_MODE\"] + df[\"BASEMENTAREA_MODE\"] + df[\"YEARS_BEGINEXPLUATATION_MODE\"] + df[\"YEARS_BUILD_MODE\"] + df[\"COMMONAREA_MODE\"] + df[\"ELEVATORS_MODE\"] + df[\"ENTRANCES_MODE\"] + df[\"FLOORSMAX_MODE\"] + df[\"FLOORSMIN_MODE\"] + df[\"LANDAREA_MODE\"] + df[\"LIVINGAPARTMENTS_MODE\"] + df[\"LIVINGAREA_MODE\"] + df[\"NONLIVINGAPARTMENTS_MODE\"] + df[\"NONLIVINGAREA_MODE\"]\n",
    "df[\"SUM_MEDI_BUILD\"] = df[\"APARTMENTS_MEDI\"] + df[\"BASEMENTAREA_MEDI\"] + df[\"YEARS_BEGINEXPLUATATION_MEDI\"] + df[\"YEARS_BUILD_MEDI\"] + df[\"COMMONAREA_MEDI\"] + df[\"ELEVATORS_MEDI\"] + df[\"ENTRANCES_MEDI\"] + df[\"FLOORSMAX_MEDI\"] + df[\"FLOORSMIN_MEDI\"] + df[\"LANDAREA_MEDI\"] + df[\"LIVINGAPARTMENTS_MEDI\"] + df[\"LIVINGAREA_MEDI\"] + df[\"NONLIVINGAPARTMENTS_MEDI\"] + df[\"NONLIVINGAREA_MEDI\"]\n",
    "df[\"SUM_DOC_FLAG\"] = df[\"FLAG_DOCUMENT_2\"] + df[\"FLAG_DOCUMENT_3\"] + df[\"FLAG_DOCUMENT_4\"] + df[\"FLAG_DOCUMENT_5\"] + df[\"FLAG_DOCUMENT_6\"] + df[\"FLAG_DOCUMENT_7\"] + df[\"FLAG_DOCUMENT_8\"] + df[\"FLAG_DOCUMENT_9\"] + df[\"FLAG_DOCUMENT_10\"] + df[\"FLAG_DOCUMENT_11\"] + df[\"FLAG_DOCUMENT_12\"] + df[\"FLAG_DOCUMENT_13\"] + df[\"FLAG_DOCUMENT_14\"] + df[\"FLAG_DOCUMENT_15\"] + df[\"FLAG_DOCUMENT_16\"] + df[\"FLAG_DOCUMENT_17\"] + df[\"FLAG_DOCUMENT_18\"] + df[\"FLAG_DOCUMENT_19\"] + df[\"FLAG_DOCUMENT_20\"] + df[\"FLAG_DOCUMENT_21\"]\n",
    "df[\"CNT_CHILDREN_DIV_DAYS_BIRTH\"] = df[\"CNT_CHILDREN\"] / df[\"DAYS_BIRTH\"]\n",
    "df[\"CNT_CHILDREN_DIV_REGION_POPULATION_RELATIVE\"] = df[\"CNT_CHILDREN\"] / df[\"REGION_POPULATION_RELATIVE\"]\n",
    "df[\"FLAG_OWN_REALTY_PROD_REGION_POPULATION_RELATIVE\"] = df[\"FLAG_OWN_REALTY\"] * df[\"REGION_POPULATION_RELATIVE\"]\n",
    "df[\"FLAG_OWN_REALTY_DIV_REGION_POPULATION_RELATIVE\"] = df[\"FLAG_OWN_REALTY\"] / df[\"REGION_POPULATION_RELATIVE\"]\n",
    "df[\"FLAG_OWN_CAR_DIV_OWN_CAR_AGE\"] = df[\"FLAG_OWN_CAR\"] / df[\"OWN_CAR_AGE\"]\n",
    "df[\"EXT_SOURCE_1_DIV_DAYS_BIRTH\"] = df[\"EXT_SOURCE_1\"] / df[\"DAYS_BIRTH\"]\n",
    "df[\"EXT_SOURCE_1_PROD_DAYS_BIRTH\"] = df[\"EXT_SOURCE_1\"] * df[\"DAYS_BIRTH\"]\n",
    "\n",
    "df[\"AVG_AGG_SYNTHETIC_TARGET\"] = df[[\"BUREAU_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"PREVIOUS_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"CREDIT_CARD_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"INSTALLMENT_AGG_SYNTHETIC_TARGET\"]].apply(np.nanmean, axis=1)\n",
    "\n",
    "df[\"SUM_AGG_SYNTHETIC_TARGET\"] = df[[\"BUREAU_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"PREVIOUS_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"CREDIT_CARD_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"INSTALLMENT_AGG_SYNTHETIC_TARGET\"]].apply(np.nansum, axis=1)\n",
    "\n",
    "df[\"MAX_AGG_SYNTHETIC_TARGET\"] = df[[\"BUREAU_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"PREVIOUS_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"CREDIT_CARD_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"INSTALLMENT_AGG_SYNTHETIC_TARGET\"]].apply(np.nanmax, axis=1)\n",
    "\n",
    "df[\"MIN_AGG_SYNTHETIC_TARGET\"] = df[[\"BUREAU_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"PREVIOUS_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"CREDIT_CARD_AGG_SYNTHETIC_TARGET\", \n",
    "                                     \"INSTALLMENT_AGG_SYNTHETIC_TARGET\"]].apply(np.nanmin, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove infinite values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.8 s\n"
     ]
    }
   ],
   "source": [
    "df.replace([-np.inf, np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove income outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.8 ms\n"
     ]
    }
   ],
   "source": [
    "df.loc[df[\"AMT_INCOME_TOTAL\"] > 500000, \"AMT_INCOME_TOTAL\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle special values for DAYS_EMPLOYED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "df.loc[df[\"DAYS_EMPLOYED\"] > 0, \"DAYS_EMPLOYED\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order `ORGANIZATION_TYPE` categories and map to integers (`org_type_map` was obtained by checking the default rates by group within the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.2 ms\n"
     ]
    }
   ],
   "source": [
    "org_type_map = {\"Trade: type 4\": 0, \"Industry: type 12\": 1, \"Transport: type 1\": 2, \"Trade: type 6\": 3,\n",
    "    \"Security Ministries\": 4, \"University\": 5, \"Police\": 6, \"Military\": 7,\n",
    "    \"Bank\": 8, \"XNA\": 9, \"Culture\": 10, \"Insurance\": 11,\n",
    "    \"Religion\": 12, \"School\": 13, \"Trade: type 5\": 14, \"Hotel\": 15,\n",
    "    \"Industry: type 10\": 16, \"Medicine\": 17, \"Services\": 18, \"Electricity\": 19,\n",
    "    \"Industry: type 9\": 20, \"Industry: type 5\": 21, \"Government\": 22, \"Trade: type 2\": 23,\n",
    "    \"Kindergarten\": 24, \"Emergency\": 25, \"Industry: type 6\": 26, \"Industry: type 2\": 27,\n",
    "    \"Telecom\": 28, \"Other\": 29, \"Transport: type 2\": 30, \"Legal Services\": 31,\n",
    "    \"Housing\": 32, \"Industry: type 7\": 33, \"Business Entity Type 1\": 34, \"Advertising\": 35,\n",
    "    \"Postal\": 36, \"Business Entity Type 2\": 37, \"Industry: type 11\": 38, \"Trade: type 1\": 39,\n",
    "    \"Mobile\": 40, \"Transport: type 4\": 41, \"Business Entity Type 3\": 42, \"Trade: type 7\": 43,\n",
    "    \"Security\": 44, \"Industry: type 4\": 45, \"Self-employed\": 46, \"Trade: type 3\": 47,\n",
    "    \"Agriculture\": 48, \"Realtor\": 49, \"Industry: type 3\": 50, \"Industry: type 1\": 51,\n",
    "    \"Cleaning\": 52, \"Construction\": 53, \"Restaurant\": 54, \"Industry: type 8\": 55,\n",
    "    \"Industry: type 13\": 56, \"Transport: type 3\": 57}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 118 ms\n"
     ]
    }
   ],
   "source": [
    "df[\"ORGANIZATION_TYPE\"] = df[\"ORGANIZATION_TYPE\"].map(org_type_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy code remaining categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.52 s\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, dummy_na=True)\n",
    "df.columns = df.columns.str.replace(\"\\s+\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove nuisance columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 502)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.12 s\n"
     ]
    }
   ],
   "source": [
    "df[\"NAME_FAMILY_STATUS_Unknown\"] = 0\n",
    "df[\"NAME_INCOME_TYPE_Maternity_leave\"] = 0\n",
    "df[\"CODE_GENDER_XNA\"] = 0\n",
    "df.drop([\"NAME_FAMILY_STATUS_Unknown\", \"NAME_INCOME_TYPE_Maternity_leave\", \"CODE_GENDER_XNA\"], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write preprocessed data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path + train_or_test + \".csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
